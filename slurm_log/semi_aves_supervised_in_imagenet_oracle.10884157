Using l_train + val + unlabeled_in_oracle for training!!
######################################################################################################################################################
Creating Dataloaders
Reading split file from data/semi_aves/l_train_val_utrain_in_oracle.txt
All good for split l_train_val_utrain_in_oracle
# images in l_train_val_utrain_in_oracle: 32599
Reading split file from data/semi_aves/u_train_in.txt
All good for split u_train_in
# images in u_train_in: 26640
Reading split file from data/semi_aves/test.txt
All good for split test
# images in test: 8000
Reading split file from data/semi_aves/test.txt
All good for split test
# images in test: 8000


labeled data : 32599, unlabeled data : 26640
validation data : 8000, test data : 8000
#classes : 200
Dataloaders created successfully!
######################################################################################################################################################
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /home/anwesha.basu/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Download failed: <urlopen error [Errno 101] Network is unreachable>
Loading model weights from local path.
using #GPUs: 1
parameters :  Namespace(MoCo=False, alg='supervised', alpha=0.1, batch_size=32, consis_coef=1.0, continue_training=False, em=0, exp_dir='semi_aves_supervised_in_imagenet_oracle', exp_prefix='results', init='imagenet', input_size=224, kd_T=1.0, load_dir='', lr=0.001, model='resnet50', num_iter=15000, num_workers=12, path_t='', print_freq=100, retrieval_split=None, root='data', task='semi_aves', threshold=0.95, trainval=False, trainval_un_in_oracle=True, unlabel='in', val_freq=200, warmup=1000, wd=0.0001)
train | Iteration 100/15000 | Loss 5.126228 | Top1 Acc 2.12% | Top5 Acc 7.84%
train | Iteration 200/15000 | Loss 4.830074 | Top1 Acc 7.28% | Top5 Acc 21.09%
Val | Iteration 200/15000 | Loss 4.864333 | Top1 Acc 9.20% | Top5 Acc 21.27%
train | Iteration 300/15000 | Loss 4.467466 | Top1 Acc 12.72% | Top5 Acc 30.16%
train | Iteration 400/15000 | Loss 4.161498 | Top1 Acc 17.59% | Top5 Acc 37.19%
Val | Iteration 400/15000 | Loss 4.167973 | Top1 Acc 15.96% | Top5 Acc 35.96%
train | Iteration 500/15000 | Loss 3.897914 | Top1 Acc 20.41% | Top5 Acc 43.41%
train | Iteration 600/15000 | Loss 3.665288 | Top1 Acc 22.66% | Top5 Acc 48.28%
Val | Iteration 600/15000 | Loss 3.703621 | Top1 Acc 20.99% | Top5 Acc 44.81%
train | Iteration 700/15000 | Loss 3.469510 | Top1 Acc 25.56% | Top5 Acc 52.34%
train | Iteration 800/15000 | Loss 3.297674 | Top1 Acc 28.09% | Top5 Acc 56.22%
Val | Iteration 800/15000 | Loss 3.328164 | Top1 Acc 26.65% | Top5 Acc 53.24%
train | Iteration 900/15000 | Loss 3.134435 | Top1 Acc 31.81% | Top5 Acc 58.78%
train | Iteration 1000/15000 | Loss 3.053370 | Top1 Acc 33.75% | Top5 Acc 58.81%
Val | Iteration 1000/15000 | Loss 3.071245 | Top1 Acc 29.59% | Top5 Acc 57.33%
train | Iteration 1100/15000 | Loss 2.916351 | Top1 Acc 35.00% | Top5 Acc 63.00%
train | Iteration 1200/15000 | Loss 2.850445 | Top1 Acc 34.53% | Top5 Acc 65.34%
Val | Iteration 1200/15000 | Loss 2.866176 | Top1 Acc 33.95% | Top5 Acc 62.59%
train | Iteration 1300/15000 | Loss 2.734682 | Top1 Acc 38.38% | Top5 Acc 66.28%
train | Iteration 1400/15000 | Loss 2.660722 | Top1 Acc 39.38% | Top5 Acc 68.00%
Val | Iteration 1400/15000 | Loss 2.669757 | Top1 Acc 37.04% | Top5 Acc 65.11%
train | Iteration 1500/15000 | Loss 2.601043 | Top1 Acc 39.66% | Top5 Acc 67.88%
train | Iteration 1600/15000 | Loss 2.574742 | Top1 Acc 39.94% | Top5 Acc 68.12%
Val | Iteration 1600/15000 | Loss 2.503107 | Top1 Acc 39.73% | Top5 Acc 68.11%
train | Iteration 1700/15000 | Loss 2.536731 | Top1 Acc 41.94% | Top5 Acc 69.03%
train | Iteration 1800/15000 | Loss 2.506888 | Top1 Acc 42.56% | Top5 Acc 69.22%
Val | Iteration 1800/15000 | Loss 2.416903 | Top1 Acc 40.05% | Top5 Acc 69.50%
train | Iteration 1900/15000 | Loss 2.425435 | Top1 Acc 43.72% | Top5 Acc 70.81%
train | Iteration 2000/15000 | Loss 2.418751 | Top1 Acc 42.66% | Top5 Acc 71.00%
Val | Iteration 2000/15000 | Loss 2.331604 | Top1 Acc 41.73% | Top5 Acc 70.95%
train | Iteration 2100/15000 | Loss 2.268928 | Top1 Acc 46.94% | Top5 Acc 73.59%
train | Iteration 2200/15000 | Loss 2.262023 | Top1 Acc 47.84% | Top5 Acc 72.91%
Val | Iteration 2200/15000 | Loss 2.213618 | Top1 Acc 44.16% | Top5 Acc 72.31%
train | Iteration 2300/15000 | Loss 2.196619 | Top1 Acc 49.03% | Top5 Acc 74.44%
train | Iteration 2400/15000 | Loss 2.200822 | Top1 Acc 47.62% | Top5 Acc 74.31%
Val | Iteration 2400/15000 | Loss 2.122497 | Top1 Acc 46.30% | Top5 Acc 74.71%
train | Iteration 2500/15000 | Loss 2.239455 | Top1 Acc 47.19% | Top5 Acc 72.75%
train | Iteration 2600/15000 | Loss 2.186134 | Top1 Acc 48.28% | Top5 Acc 73.88%
Val | Iteration 2600/15000 | Loss 2.072389 | Top1 Acc 47.52% | Top5 Acc 75.94%
train | Iteration 2700/15000 | Loss 2.161641 | Top1 Acc 48.28% | Top5 Acc 75.25%
train | Iteration 2800/15000 | Loss 2.136571 | Top1 Acc 48.53% | Top5 Acc 74.97%
Val | Iteration 2800/15000 | Loss 2.063343 | Top1 Acc 46.64% | Top5 Acc 75.58%
train | Iteration 2900/15000 | Loss 2.055464 | Top1 Acc 50.47% | Top5 Acc 76.75%
train | Iteration 3000/15000 | Loss 2.079613 | Top1 Acc 49.44% | Top5 Acc 75.81%
Val | Iteration 3000/15000 | Loss 1.962261 | Top1 Acc 49.51% | Top5 Acc 77.62%
train | Iteration 3100/15000 | Loss 2.032158 | Top1 Acc 52.47% | Top5 Acc 77.56%
train | Iteration 3200/15000 | Loss 1.956890 | Top1 Acc 53.16% | Top5 Acc 77.94%
Val | Iteration 3200/15000 | Loss 1.909232 | Top1 Acc 50.30% | Top5 Acc 78.11%
train | Iteration 3300/15000 | Loss 1.954111 | Top1 Acc 53.25% | Top5 Acc 77.12%
train | Iteration 3400/15000 | Loss 1.949640 | Top1 Acc 53.25% | Top5 Acc 77.94%
Val | Iteration 3400/15000 | Loss 1.852343 | Top1 Acc 51.16% | Top5 Acc 79.41%
train | Iteration 3500/15000 | Loss 1.950593 | Top1 Acc 51.94% | Top5 Acc 78.50%
train | Iteration 3600/15000 | Loss 1.923481 | Top1 Acc 53.06% | Top5 Acc 79.31%
Val | Iteration 3600/15000 | Loss 1.845664 | Top1 Acc 51.65% | Top5 Acc 79.61%
train | Iteration 3700/15000 | Loss 1.941264 | Top1 Acc 52.91% | Top5 Acc 76.94%
train | Iteration 3800/15000 | Loss 1.958338 | Top1 Acc 53.16% | Top5 Acc 78.19%
Val | Iteration 3800/15000 | Loss 1.786636 | Top1 Acc 53.08% | Top5 Acc 80.49%
train | Iteration 3900/15000 | Loss 1.910240 | Top1 Acc 54.38% | Top5 Acc 77.69%
train | Iteration 4000/15000 | Loss 1.905270 | Top1 Acc 53.38% | Top5 Acc 78.00%
Val | Iteration 4000/15000 | Loss 1.739984 | Top1 Acc 54.02% | Top5 Acc 81.74%
train | Iteration 4100/15000 | Loss 1.823991 | Top1 Acc 56.28% | Top5 Acc 79.16%
train | Iteration 4200/15000 | Loss 1.790130 | Top1 Acc 56.50% | Top5 Acc 80.50%
Val | Iteration 4200/15000 | Loss 1.724150 | Top1 Acc 53.70% | Top5 Acc 81.75%
train | Iteration 4300/15000 | Loss 1.757030 | Top1 Acc 56.62% | Top5 Acc 80.59%
train | Iteration 4400/15000 | Loss 1.780384 | Top1 Acc 56.88% | Top5 Acc 79.88%
Val | Iteration 4400/15000 | Loss 1.684534 | Top1 Acc 55.42% | Top5 Acc 81.96%
train | Iteration 4500/15000 | Loss 1.743853 | Top1 Acc 57.94% | Top5 Acc 80.25%
train | Iteration 4600/15000 | Loss 1.790819 | Top1 Acc 56.84% | Top5 Acc 79.62%
Val | Iteration 4600/15000 | Loss 1.647732 | Top1 Acc 57.00% | Top5 Acc 82.03%
train | Iteration 4700/15000 | Loss 1.763250 | Top1 Acc 57.50% | Top5 Acc 80.12%
train | Iteration 4800/15000 | Loss 1.795083 | Top1 Acc 55.88% | Top5 Acc 79.62%
Val | Iteration 4800/15000 | Loss 1.622984 | Top1 Acc 56.67% | Top5 Acc 82.81%
train | Iteration 4900/15000 | Loss 1.762936 | Top1 Acc 57.00% | Top5 Acc 79.59%
train | Iteration 5000/15000 | Loss 1.794590 | Top1 Acc 55.75% | Top5 Acc 79.94%
Val | Iteration 5000/15000 | Loss 1.622418 | Top1 Acc 56.76% | Top5 Acc 83.25%
train | Iteration 5100/15000 | Loss 1.697117 | Top1 Acc 57.91% | Top5 Acc 81.97%
train | Iteration 5200/15000 | Loss 1.626091 | Top1 Acc 60.91% | Top5 Acc 81.34%
Val | Iteration 5200/15000 | Loss 1.601003 | Top1 Acc 57.55% | Top5 Acc 83.41%
train | Iteration 5300/15000 | Loss 1.641366 | Top1 Acc 60.03% | Top5 Acc 82.16%
train | Iteration 5400/15000 | Loss 1.658960 | Top1 Acc 59.12% | Top5 Acc 81.41%
Val | Iteration 5400/15000 | Loss 1.615072 | Top1 Acc 57.08% | Top5 Acc 83.30%
train | Iteration 5500/15000 | Loss 1.623332 | Top1 Acc 60.19% | Top5 Acc 82.28%
train | Iteration 5600/15000 | Loss 1.637673 | Top1 Acc 60.44% | Top5 Acc 82.31%
Val | Iteration 5600/15000 | Loss 1.567803 | Top1 Acc 58.06% | Top5 Acc 83.65%
train | Iteration 5700/15000 | Loss 1.704393 | Top1 Acc 57.69% | Top5 Acc 80.94%
train | Iteration 5800/15000 | Loss 1.631522 | Top1 Acc 60.22% | Top5 Acc 81.91%
Val | Iteration 5800/15000 | Loss 1.571911 | Top1 Acc 58.59% | Top5 Acc 83.91%
train | Iteration 5900/15000 | Loss 1.590631 | Top1 Acc 60.78% | Top5 Acc 82.62%
train | Iteration 6000/15000 | Loss 1.647004 | Top1 Acc 59.91% | Top5 Acc 81.25%
Val | Iteration 6000/15000 | Loss 1.544973 | Top1 Acc 58.96% | Top5 Acc 84.25%
train | Iteration 6100/15000 | Loss 1.628655 | Top1 Acc 60.09% | Top5 Acc 82.72%
train | Iteration 6200/15000 | Loss 1.504540 | Top1 Acc 63.59% | Top5 Acc 84.09%
Val | Iteration 6200/15000 | Loss 1.503155 | Top1 Acc 60.06% | Top5 Acc 84.76%
train | Iteration 6300/15000 | Loss 1.555832 | Top1 Acc 62.31% | Top5 Acc 83.25%
train | Iteration 6400/15000 | Loss 1.551494 | Top1 Acc 61.75% | Top5 Acc 83.28%
Val | Iteration 6400/15000 | Loss 1.495407 | Top1 Acc 59.91% | Top5 Acc 85.12%
train | Iteration 6500/15000 | Loss 1.540783 | Top1 Acc 62.72% | Top5 Acc 83.31%
train | Iteration 6600/15000 | Loss 1.555383 | Top1 Acc 61.59% | Top5 Acc 82.84%
Val | Iteration 6600/15000 | Loss 1.495161 | Top1 Acc 60.24% | Top5 Acc 85.12%
train | Iteration 6700/15000 | Loss 1.517228 | Top1 Acc 61.41% | Top5 Acc 84.16%
train | Iteration 6800/15000 | Loss 1.561342 | Top1 Acc 62.62% | Top5 Acc 82.31%
Val | Iteration 6800/15000 | Loss 1.493393 | Top1 Acc 60.10% | Top5 Acc 84.41%
train | Iteration 6900/15000 | Loss 1.485876 | Top1 Acc 62.66% | Top5 Acc 84.22%
train | Iteration 7000/15000 | Loss 1.541815 | Top1 Acc 61.22% | Top5 Acc 82.88%
Val | Iteration 7000/15000 | Loss 1.452799 | Top1 Acc 61.79% | Top5 Acc 85.55%
train | Iteration 7100/15000 | Loss 1.476032 | Top1 Acc 63.41% | Top5 Acc 84.62%
train | Iteration 7200/15000 | Loss 1.474528 | Top1 Acc 63.84% | Top5 Acc 84.12%
Val | Iteration 7200/15000 | Loss 1.452664 | Top1 Acc 61.31% | Top5 Acc 85.24%
train | Iteration 7300/15000 | Loss 1.428069 | Top1 Acc 64.19% | Top5 Acc 84.88%
train | Iteration 7400/15000 | Loss 1.455088 | Top1 Acc 64.53% | Top5 Acc 84.94%
Val | Iteration 7400/15000 | Loss 1.424170 | Top1 Acc 62.01% | Top5 Acc 85.74%
train | Iteration 7500/15000 | Loss 1.458003 | Top1 Acc 63.03% | Top5 Acc 84.22%
train | Iteration 7600/15000 | Loss 1.480229 | Top1 Acc 63.31% | Top5 Acc 84.22%
Val | Iteration 7600/15000 | Loss 1.419118 | Top1 Acc 62.31% | Top5 Acc 85.36%
train | Iteration 7700/15000 | Loss 1.468337 | Top1 Acc 63.59% | Top5 Acc 83.97%
train | Iteration 7800/15000 | Loss 1.414317 | Top1 Acc 64.16% | Top5 Acc 85.22%
Val | Iteration 7800/15000 | Loss 1.403838 | Top1 Acc 62.41% | Top5 Acc 85.88%
train | Iteration 7900/15000 | Loss 1.393915 | Top1 Acc 65.22% | Top5 Acc 84.84%
train | Iteration 8000/15000 | Loss 1.393974 | Top1 Acc 65.38% | Top5 Acc 84.69%
Val | Iteration 8000/15000 | Loss 1.395217 | Top1 Acc 62.86% | Top5 Acc 86.46%
train | Iteration 8100/15000 | Loss 1.402028 | Top1 Acc 65.41% | Top5 Acc 85.53%
train | Iteration 8200/15000 | Loss 1.424605 | Top1 Acc 65.97% | Top5 Acc 84.94%
Val | Iteration 8200/15000 | Loss 1.395174 | Top1 Acc 62.83% | Top5 Acc 86.28%
train | Iteration 8300/15000 | Loss 1.353661 | Top1 Acc 67.03% | Top5 Acc 86.59%
train | Iteration 8400/15000 | Loss 1.347494 | Top1 Acc 67.44% | Top5 Acc 85.78%
Val | Iteration 8400/15000 | Loss 1.379148 | Top1 Acc 63.10% | Top5 Acc 86.44%
train | Iteration 8500/15000 | Loss 1.425390 | Top1 Acc 65.09% | Top5 Acc 84.03%
train | Iteration 8600/15000 | Loss 1.361627 | Top1 Acc 65.97% | Top5 Acc 85.69%
Val | Iteration 8600/15000 | Loss 1.368968 | Top1 Acc 64.30% | Top5 Acc 86.36%
train | Iteration 8700/15000 | Loss 1.421512 | Top1 Acc 64.50% | Top5 Acc 84.44%
train | Iteration 8800/15000 | Loss 1.364785 | Top1 Acc 66.81% | Top5 Acc 86.00%
Val | Iteration 8800/15000 | Loss 1.354134 | Top1 Acc 64.04% | Top5 Acc 86.61%
train | Iteration 8900/15000 | Loss 1.373291 | Top1 Acc 66.16% | Top5 Acc 85.41%
train | Iteration 9000/15000 | Loss 1.396864 | Top1 Acc 65.47% | Top5 Acc 84.66%
Val | Iteration 9000/15000 | Loss 1.354078 | Top1 Acc 63.56% | Top5 Acc 86.58%
train | Iteration 9100/15000 | Loss 1.375986 | Top1 Acc 66.44% | Top5 Acc 85.53%
train | Iteration 9200/15000 | Loss 1.316876 | Top1 Acc 67.38% | Top5 Acc 86.75%
Val | Iteration 9200/15000 | Loss 1.354058 | Top1 Acc 63.46% | Top5 Acc 86.61%
train | Iteration 9300/15000 | Loss 1.313535 | Top1 Acc 67.66% | Top5 Acc 86.41%
train | Iteration 9400/15000 | Loss 1.294829 | Top1 Acc 68.00% | Top5 Acc 86.53%
Val | Iteration 9400/15000 | Loss 1.347308 | Top1 Acc 63.89% | Top5 Acc 86.83%
train | Iteration 9500/15000 | Loss 1.346880 | Top1 Acc 66.94% | Top5 Acc 86.00%
train | Iteration 9600/15000 | Loss 1.278861 | Top1 Acc 68.25% | Top5 Acc 86.44%
Val | Iteration 9600/15000 | Loss 1.321822 | Top1 Acc 64.71% | Top5 Acc 87.09%
train | Iteration 9700/15000 | Loss 1.392266 | Top1 Acc 66.22% | Top5 Acc 84.78%
train | Iteration 9800/15000 | Loss 1.273054 | Top1 Acc 68.69% | Top5 Acc 86.78%
Val | Iteration 9800/15000 | Loss 1.326284 | Top1 Acc 64.39% | Top5 Acc 86.76%
train | Iteration 9900/15000 | Loss 1.294813 | Top1 Acc 68.41% | Top5 Acc 86.25%
train | Iteration 10000/15000 | Loss 1.317990 | Top1 Acc 68.03% | Top5 Acc 86.62%
Val | Iteration 10000/15000 | Loss 1.315546 | Top1 Acc 64.83% | Top5 Acc 86.81%
train | Iteration 10100/15000 | Loss 1.313426 | Top1 Acc 67.38% | Top5 Acc 86.28%
train | Iteration 10200/15000 | Loss 1.283814 | Top1 Acc 69.12% | Top5 Acc 87.38%
Val | Iteration 10200/15000 | Loss 1.304185 | Top1 Acc 65.21% | Top5 Acc 87.44%
train | Iteration 10300/15000 | Loss 1.293383 | Top1 Acc 69.03% | Top5 Acc 86.97%
train | Iteration 10400/15000 | Loss 1.269399 | Top1 Acc 69.03% | Top5 Acc 87.12%
Val | Iteration 10400/15000 | Loss 1.292698 | Top1 Acc 65.94% | Top5 Acc 87.22%
train | Iteration 10500/15000 | Loss 1.262282 | Top1 Acc 68.84% | Top5 Acc 87.25%
train | Iteration 10600/15000 | Loss 1.317500 | Top1 Acc 67.94% | Top5 Acc 85.94%
Val | Iteration 10600/15000 | Loss 1.296937 | Top1 Acc 65.38% | Top5 Acc 87.38%
train | Iteration 10700/15000 | Loss 1.353831 | Top1 Acc 67.19% | Top5 Acc 85.56%
train | Iteration 10800/15000 | Loss 1.248065 | Top1 Acc 70.03% | Top5 Acc 86.81%
Val | Iteration 10800/15000 | Loss 1.293040 | Top1 Acc 65.39% | Top5 Acc 87.31%
train | Iteration 10900/15000 | Loss 1.274682 | Top1 Acc 68.66% | Top5 Acc 86.16%
train | Iteration 11000/15000 | Loss 1.277487 | Top1 Acc 68.75% | Top5 Acc 86.28%
Val | Iteration 11000/15000 | Loss 1.288471 | Top1 Acc 65.58% | Top5 Acc 87.39%
train | Iteration 11100/15000 | Loss 1.295993 | Top1 Acc 67.75% | Top5 Acc 86.09%
train | Iteration 11200/15000 | Loss 1.262955 | Top1 Acc 68.97% | Top5 Acc 86.28%
Val | Iteration 11200/15000 | Loss 1.277479 | Top1 Acc 65.80% | Top5 Acc 87.59%
train | Iteration 11300/15000 | Loss 1.215380 | Top1 Acc 70.78% | Top5 Acc 87.75%
train | Iteration 11400/15000 | Loss 1.206620 | Top1 Acc 70.03% | Top5 Acc 88.09%
Val | Iteration 11400/15000 | Loss 1.267051 | Top1 Acc 66.10% | Top5 Acc 87.71%
train | Iteration 11500/15000 | Loss 1.251706 | Top1 Acc 69.66% | Top5 Acc 87.03%
train | Iteration 11600/15000 | Loss 1.161760 | Top1 Acc 71.59% | Top5 Acc 88.03%
Val | Iteration 11600/15000 | Loss 1.276145 | Top1 Acc 66.10% | Top5 Acc 87.70%
train | Iteration 11700/15000 | Loss 1.251083 | Top1 Acc 69.41% | Top5 Acc 86.72%
train | Iteration 11800/15000 | Loss 1.240912 | Top1 Acc 69.28% | Top5 Acc 87.16%
Val | Iteration 11800/15000 | Loss 1.263460 | Top1 Acc 66.15% | Top5 Acc 87.91%
train | Iteration 11900/15000 | Loss 1.201352 | Top1 Acc 70.19% | Top5 Acc 88.38%
train | Iteration 12000/15000 | Loss 1.245804 | Top1 Acc 70.50% | Top5 Acc 87.19%
Val | Iteration 12000/15000 | Loss 1.265075 | Top1 Acc 66.14% | Top5 Acc 87.91%
train | Iteration 12100/15000 | Loss 1.251703 | Top1 Acc 69.34% | Top5 Acc 87.16%
train | Iteration 12200/15000 | Loss 1.204075 | Top1 Acc 70.22% | Top5 Acc 87.78%
Val | Iteration 12200/15000 | Loss 1.264548 | Top1 Acc 66.62% | Top5 Acc 87.81%
train | Iteration 12300/15000 | Loss 1.231815 | Top1 Acc 69.94% | Top5 Acc 87.03%
train | Iteration 12400/15000 | Loss 1.219605 | Top1 Acc 69.72% | Top5 Acc 87.34%
Val | Iteration 12400/15000 | Loss 1.259573 | Top1 Acc 66.71% | Top5 Acc 87.76%
train | Iteration 12500/15000 | Loss 1.249303 | Top1 Acc 70.50% | Top5 Acc 86.50%
train | Iteration 12600/15000 | Loss 1.200403 | Top1 Acc 70.56% | Top5 Acc 87.78%
Val | Iteration 12600/15000 | Loss 1.263521 | Top1 Acc 66.39% | Top5 Acc 87.76%
train | Iteration 12700/15000 | Loss 1.220709 | Top1 Acc 69.94% | Top5 Acc 87.19%
train | Iteration 12800/15000 | Loss 1.216460 | Top1 Acc 70.12% | Top5 Acc 87.16%
Val | Iteration 12800/15000 | Loss 1.263624 | Top1 Acc 66.33% | Top5 Acc 88.08%
train | Iteration 12900/15000 | Loss 1.266404 | Top1 Acc 69.16% | Top5 Acc 87.09%
train | Iteration 13000/15000 | Loss 1.187735 | Top1 Acc 71.22% | Top5 Acc 88.56%
Val | Iteration 13000/15000 | Loss 1.254745 | Top1 Acc 66.70% | Top5 Acc 88.04%
train | Iteration 13100/15000 | Loss 1.190544 | Top1 Acc 70.88% | Top5 Acc 88.41%
train | Iteration 13200/15000 | Loss 1.167927 | Top1 Acc 71.62% | Top5 Acc 88.09%
Val | Iteration 13200/15000 | Loss 1.257477 | Top1 Acc 66.16% | Top5 Acc 87.88%
train | Iteration 13300/15000 | Loss 1.191991 | Top1 Acc 70.72% | Top5 Acc 87.62%
train | Iteration 13400/15000 | Loss 1.178594 | Top1 Acc 70.88% | Top5 Acc 88.53%
Val | Iteration 13400/15000 | Loss 1.254455 | Top1 Acc 66.51% | Top5 Acc 88.11%
train | Iteration 13500/15000 | Loss 1.239010 | Top1 Acc 70.41% | Top5 Acc 86.50%
train | Iteration 13600/15000 | Loss 1.196434 | Top1 Acc 69.91% | Top5 Acc 87.59%
Val | Iteration 13600/15000 | Loss 1.250712 | Top1 Acc 66.67% | Top5 Acc 87.86%
train | Iteration 13700/15000 | Loss 1.229232 | Top1 Acc 70.34% | Top5 Acc 87.38%
train | Iteration 13800/15000 | Loss 1.213794 | Top1 Acc 70.06% | Top5 Acc 87.41%
Val | Iteration 13800/15000 | Loss 1.253619 | Top1 Acc 66.46% | Top5 Acc 87.99%
train | Iteration 13900/15000 | Loss 1.214007 | Top1 Acc 70.09% | Top5 Acc 87.78%
train | Iteration 14000/15000 | Loss 1.232428 | Top1 Acc 70.38% | Top5 Acc 86.94%
Val | Iteration 14000/15000 | Loss 1.252959 | Top1 Acc 66.51% | Top5 Acc 88.10%
train | Iteration 14100/15000 | Loss 1.207990 | Top1 Acc 70.56% | Top5 Acc 87.47%
train | Iteration 14200/15000 | Loss 1.201686 | Top1 Acc 70.94% | Top5 Acc 87.16%
Val | Iteration 14200/15000 | Loss 1.246611 | Top1 Acc 66.66% | Top5 Acc 87.89%
train | Iteration 14300/15000 | Loss 1.191509 | Top1 Acc 71.31% | Top5 Acc 87.78%
train | Iteration 14400/15000 | Loss 1.227593 | Top1 Acc 69.31% | Top5 Acc 87.31%
Val | Iteration 14400/15000 | Loss 1.255836 | Top1 Acc 66.46% | Top5 Acc 88.08%
train | Iteration 14500/15000 | Loss 1.192562 | Top1 Acc 70.75% | Top5 Acc 88.12%
train | Iteration 14600/15000 | Loss 1.157494 | Top1 Acc 71.81% | Top5 Acc 88.22%
Val | Iteration 14600/15000 | Loss 1.260369 | Top1 Acc 66.16% | Top5 Acc 88.15%
train | Iteration 14700/15000 | Loss 1.188429 | Top1 Acc 71.56% | Top5 Acc 87.84%
train | Iteration 14800/15000 | Loss 1.218044 | Top1 Acc 71.31% | Top5 Acc 87.44%
Val | Iteration 14800/15000 | Loss 1.262217 | Top1 Acc 66.24% | Top5 Acc 87.91%
train | Iteration 14900/15000 | Loss 1.180208 | Top1 Acc 71.59% | Top5 Acc 87.69%
train | Iteration 15000/15000 | Loss 1.197971 | Top1 Acc 70.03% | Top5 Acc 87.69%
Val | Iteration 15000/15000 | Loss 1.256057 | Top1 Acc 66.31% | Top5 Acc 87.99%
Training complete in 27m 43s
Best val Acc: 66.71%
testLast Loss: 1.2557 Top1 Acc: 66.26% Top5 Acc: 88.01%
testBest Loss: 1.2596 Top1 Acc: 66.71% Top5 Acc: 87.76%
