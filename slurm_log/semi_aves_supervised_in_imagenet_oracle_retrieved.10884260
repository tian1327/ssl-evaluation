Using l_train + val + unlabeled_in_oracle + retrieved data for training!!
######################################################################################################################################################
Creating Dataloaders
Root path for split file l_train_val_utrain_in_oracle_T2T500+T2I0.25 is /scratch/group/real-fs
Reading split file from data/semi_aves/l_train_val_utrain_in_oracle_T2T500+T2I0.25.txt
All good for split l_train_val_utrain_in_oracle_T2T500+T2I0.25
# images in l_train_val_utrain_in_oracle_T2T500+T2I0.25: 76241
Reading split file from data/semi_aves/u_train_in.txt
All good for split u_train_in
# images in u_train_in: 26640
Reading split file from data/semi_aves/test.txt
All good for split test
# images in test: 8000
Reading split file from data/semi_aves/test.txt
All good for split test
# images in test: 8000


labeled data : 76241, unlabeled data : 26640
validation data : 8000, test data : 8000
#classes : 200
Dataloaders created successfully!
######################################################################################################################################################
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /home/anwesha.basu/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Download failed: <urlopen error [Errno 101] Network is unreachable>
Loading model weights from local path.
using #GPUs: 1
parameters :  Namespace(MoCo=False, alg='supervised', alpha=0.1, batch_size=32, consis_coef=1.0, continue_training=False, em=0, exp_dir='semi_aves_supervised_in_imagenet_oracle_retrieved', exp_prefix='results', init='imagenet', input_size=224, kd_T=1.0, load_dir='', lr=0.001, model='resnet50', num_iter=25000, num_workers=12, path_t='', print_freq=100, retrieval_split='T2T500+T2I0.25', root='data', task='semi_aves', threshold=0.95, trainval=False, trainval_un_in_oracle=True, unlabel='in', val_freq=200, warmup=1000, wd=0.0001)
train | Iteration 100/25000 | Loss 5.030772 | Top1 Acc 4.25% | Top5 Acc 11.62%
train | Iteration 200/25000 | Loss 4.615640 | Top1 Acc 13.47% | Top5 Acc 28.94%
Val | Iteration 200/25000 | Loss 4.931022 | Top1 Acc 9.62% | Top5 Acc 20.25%
train | Iteration 300/25000 | Loss 4.165744 | Top1 Acc 19.91% | Top5 Acc 39.47%
train | Iteration 400/25000 | Loss 3.711521 | Top1 Acc 27.53% | Top5 Acc 49.69%
Val | Iteration 400/25000 | Loss 4.368785 | Top1 Acc 15.66% | Top5 Acc 31.99%
train | Iteration 500/25000 | Loss 3.442360 | Top1 Acc 29.06% | Top5 Acc 53.34%
train | Iteration 600/25000 | Loss 3.261660 | Top1 Acc 33.00% | Top5 Acc 57.53%
Val | Iteration 600/25000 | Loss 3.959994 | Top1 Acc 19.95% | Top5 Acc 39.17%
train | Iteration 700/25000 | Loss 3.058625 | Top1 Acc 34.53% | Top5 Acc 59.25%
train | Iteration 800/25000 | Loss 2.840277 | Top1 Acc 39.31% | Top5 Acc 64.75%
Val | Iteration 800/25000 | Loss 3.656897 | Top1 Acc 24.06% | Top5 Acc 45.23%
train | Iteration 900/25000 | Loss 2.782713 | Top1 Acc 39.47% | Top5 Acc 64.88%
train | Iteration 1000/25000 | Loss 2.640960 | Top1 Acc 42.12% | Top5 Acc 67.75%
Val | Iteration 1000/25000 | Loss 3.421697 | Top1 Acc 25.91% | Top5 Acc 49.23%
train | Iteration 1100/25000 | Loss 2.562813 | Top1 Acc 42.06% | Top5 Acc 67.38%
train | Iteration 1200/25000 | Loss 2.437578 | Top1 Acc 45.53% | Top5 Acc 70.25%
Val | Iteration 1200/25000 | Loss 3.231525 | Top1 Acc 28.60% | Top5 Acc 53.14%
train | Iteration 1300/25000 | Loss 2.424228 | Top1 Acc 44.91% | Top5 Acc 71.06%
train | Iteration 1400/25000 | Loss 2.322571 | Top1 Acc 47.09% | Top5 Acc 72.66%
Val | Iteration 1400/25000 | Loss 3.059806 | Top1 Acc 31.71% | Top5 Acc 56.35%
train | Iteration 1500/25000 | Loss 2.240107 | Top1 Acc 48.81% | Top5 Acc 72.78%
train | Iteration 1600/25000 | Loss 2.204309 | Top1 Acc 49.03% | Top5 Acc 73.56%
Val | Iteration 1600/25000 | Loss 2.920964 | Top1 Acc 33.29% | Top5 Acc 59.60%
train | Iteration 1700/25000 | Loss 2.234578 | Top1 Acc 48.41% | Top5 Acc 73.66%
train | Iteration 1800/25000 | Loss 2.091710 | Top1 Acc 50.62% | Top5 Acc 75.88%
Val | Iteration 1800/25000 | Loss 2.797332 | Top1 Acc 34.96% | Top5 Acc 61.75%
train | Iteration 1900/25000 | Loss 2.160770 | Top1 Acc 48.75% | Top5 Acc 74.34%
train | Iteration 2000/25000 | Loss 2.070045 | Top1 Acc 51.34% | Top5 Acc 76.19%
Val | Iteration 2000/25000 | Loss 2.665551 | Top1 Acc 36.62% | Top5 Acc 64.33%
train | Iteration 2100/25000 | Loss 2.008487 | Top1 Acc 52.88% | Top5 Acc 76.94%
train | Iteration 2200/25000 | Loss 1.968933 | Top1 Acc 53.59% | Top5 Acc 77.75%
Val | Iteration 2200/25000 | Loss 2.592341 | Top1 Acc 38.61% | Top5 Acc 65.88%
train | Iteration 2300/25000 | Loss 1.950208 | Top1 Acc 54.66% | Top5 Acc 77.69%
train | Iteration 2400/25000 | Loss 1.930415 | Top1 Acc 53.91% | Top5 Acc 77.44%
Val | Iteration 2400/25000 | Loss 2.485630 | Top1 Acc 39.38% | Top5 Acc 67.24%
train | Iteration 2500/25000 | Loss 1.845461 | Top1 Acc 56.19% | Top5 Acc 78.81%
train | Iteration 2600/25000 | Loss 1.856600 | Top1 Acc 56.12% | Top5 Acc 80.09%
Val | Iteration 2600/25000 | Loss 2.437922 | Top1 Acc 40.95% | Top5 Acc 68.80%
train | Iteration 2700/25000 | Loss 1.773130 | Top1 Acc 57.16% | Top5 Acc 80.81%
train | Iteration 2800/25000 | Loss 1.794307 | Top1 Acc 56.09% | Top5 Acc 80.50%
Val | Iteration 2800/25000 | Loss 2.377977 | Top1 Acc 42.36% | Top5 Acc 69.88%
train | Iteration 2900/25000 | Loss 1.801791 | Top1 Acc 56.16% | Top5 Acc 80.12%
train | Iteration 3000/25000 | Loss 1.757380 | Top1 Acc 57.78% | Top5 Acc 80.25%
Val | Iteration 3000/25000 | Loss 2.281716 | Top1 Acc 43.67% | Top5 Acc 71.58%
train | Iteration 3100/25000 | Loss 1.777373 | Top1 Acc 56.91% | Top5 Acc 80.22%
train | Iteration 3200/25000 | Loss 1.717057 | Top1 Acc 58.44% | Top5 Acc 81.16%
Val | Iteration 3200/25000 | Loss 2.198390 | Top1 Acc 45.31% | Top5 Acc 72.70%
train | Iteration 3300/25000 | Loss 1.731047 | Top1 Acc 58.25% | Top5 Acc 80.84%
train | Iteration 3400/25000 | Loss 1.671350 | Top1 Acc 60.09% | Top5 Acc 81.00%
Val | Iteration 3400/25000 | Loss 2.209291 | Top1 Acc 45.30% | Top5 Acc 71.85%
train | Iteration 3500/25000 | Loss 1.669657 | Top1 Acc 59.22% | Top5 Acc 81.59%
train | Iteration 3600/25000 | Loss 1.704084 | Top1 Acc 58.72% | Top5 Acc 81.81%
Val | Iteration 3600/25000 | Loss 2.163679 | Top1 Acc 46.04% | Top5 Acc 73.46%
train | Iteration 3700/25000 | Loss 1.693652 | Top1 Acc 59.16% | Top5 Acc 80.62%
train | Iteration 3800/25000 | Loss 1.711593 | Top1 Acc 59.34% | Top5 Acc 80.78%
Val | Iteration 3800/25000 | Loss 2.106491 | Top1 Acc 46.81% | Top5 Acc 73.75%
train | Iteration 3900/25000 | Loss 1.666373 | Top1 Acc 59.50% | Top5 Acc 81.47%
train | Iteration 4000/25000 | Loss 1.583573 | Top1 Acc 60.81% | Top5 Acc 82.91%
Val | Iteration 4000/25000 | Loss 2.085553 | Top1 Acc 47.30% | Top5 Acc 74.41%
train | Iteration 4100/25000 | Loss 1.621677 | Top1 Acc 60.47% | Top5 Acc 81.97%
train | Iteration 4200/25000 | Loss 1.647806 | Top1 Acc 59.62% | Top5 Acc 81.28%
Val | Iteration 4200/25000 | Loss 2.029064 | Top1 Acc 48.11% | Top5 Acc 75.89%
train | Iteration 4300/25000 | Loss 1.572347 | Top1 Acc 61.72% | Top5 Acc 82.78%
train | Iteration 4400/25000 | Loss 1.563624 | Top1 Acc 62.09% | Top5 Acc 82.47%
Val | Iteration 4400/25000 | Loss 1.979903 | Top1 Acc 49.70% | Top5 Acc 77.03%
train | Iteration 4500/25000 | Loss 1.576044 | Top1 Acc 60.53% | Top5 Acc 82.75%
train | Iteration 4600/25000 | Loss 1.520691 | Top1 Acc 63.06% | Top5 Acc 83.19%
Val | Iteration 4600/25000 | Loss 1.988893 | Top1 Acc 49.29% | Top5 Acc 76.30%
train | Iteration 4700/25000 | Loss 1.574469 | Top1 Acc 61.06% | Top5 Acc 81.97%
train | Iteration 4800/25000 | Loss 1.493146 | Top1 Acc 62.78% | Top5 Acc 83.53%
Val | Iteration 4800/25000 | Loss 1.955996 | Top1 Acc 49.90% | Top5 Acc 77.21%
train | Iteration 4900/25000 | Loss 1.508941 | Top1 Acc 62.34% | Top5 Acc 83.59%
train | Iteration 5000/25000 | Loss 1.485484 | Top1 Acc 63.41% | Top5 Acc 84.06%
Val | Iteration 5000/25000 | Loss 1.870865 | Top1 Acc 51.84% | Top5 Acc 78.33%
train | Iteration 5100/25000 | Loss 1.472090 | Top1 Acc 63.91% | Top5 Acc 83.94%
train | Iteration 5200/25000 | Loss 1.514431 | Top1 Acc 62.31% | Top5 Acc 83.50%
Val | Iteration 5200/25000 | Loss 1.838747 | Top1 Acc 52.77% | Top5 Acc 79.45%
train | Iteration 5300/25000 | Loss 1.479657 | Top1 Acc 63.50% | Top5 Acc 83.94%
train | Iteration 5400/25000 | Loss 1.445949 | Top1 Acc 64.06% | Top5 Acc 84.47%
Val | Iteration 5400/25000 | Loss 1.847529 | Top1 Acc 52.51% | Top5 Acc 79.08%
train | Iteration 5500/25000 | Loss 1.548269 | Top1 Acc 61.72% | Top5 Acc 82.78%
train | Iteration 5600/25000 | Loss 1.492892 | Top1 Acc 63.28% | Top5 Acc 83.19%
Val | Iteration 5600/25000 | Loss 1.817497 | Top1 Acc 52.74% | Top5 Acc 79.79%
train | Iteration 5700/25000 | Loss 1.417813 | Top1 Acc 64.66% | Top5 Acc 84.47%
train | Iteration 5800/25000 | Loss 1.441689 | Top1 Acc 63.53% | Top5 Acc 84.56%
Val | Iteration 5800/25000 | Loss 1.774775 | Top1 Acc 53.65% | Top5 Acc 80.31%
train | Iteration 5900/25000 | Loss 1.407337 | Top1 Acc 65.50% | Top5 Acc 84.19%
train | Iteration 6000/25000 | Loss 1.434576 | Top1 Acc 64.75% | Top5 Acc 83.88%
Val | Iteration 6000/25000 | Loss 1.771306 | Top1 Acc 53.56% | Top5 Acc 80.45%
train | Iteration 6100/25000 | Loss 1.456412 | Top1 Acc 64.16% | Top5 Acc 83.97%
train | Iteration 6200/25000 | Loss 1.395644 | Top1 Acc 65.28% | Top5 Acc 84.50%
Val | Iteration 6200/25000 | Loss 1.773712 | Top1 Acc 53.23% | Top5 Acc 80.51%
train | Iteration 6300/25000 | Loss 1.390387 | Top1 Acc 66.00% | Top5 Acc 84.56%
train | Iteration 6400/25000 | Loss 1.367453 | Top1 Acc 65.28% | Top5 Acc 85.19%
Val | Iteration 6400/25000 | Loss 1.762982 | Top1 Acc 54.34% | Top5 Acc 80.34%
train | Iteration 6500/25000 | Loss 1.389109 | Top1 Acc 66.31% | Top5 Acc 84.94%
train | Iteration 6600/25000 | Loss 1.362952 | Top1 Acc 64.44% | Top5 Acc 85.59%
Val | Iteration 6600/25000 | Loss 1.771502 | Top1 Acc 53.60% | Top5 Acc 80.26%
train | Iteration 6700/25000 | Loss 1.441236 | Top1 Acc 64.53% | Top5 Acc 83.50%
train | Iteration 6800/25000 | Loss 1.333770 | Top1 Acc 66.69% | Top5 Acc 86.22%
Val | Iteration 6800/25000 | Loss 1.692639 | Top1 Acc 55.60% | Top5 Acc 81.72%
train | Iteration 6900/25000 | Loss 1.354012 | Top1 Acc 66.03% | Top5 Acc 85.72%
train | Iteration 7000/25000 | Loss 1.355098 | Top1 Acc 66.72% | Top5 Acc 85.84%
Val | Iteration 7000/25000 | Loss 1.673175 | Top1 Acc 55.96% | Top5 Acc 82.05%
train | Iteration 7100/25000 | Loss 1.383327 | Top1 Acc 66.19% | Top5 Acc 84.38%
train | Iteration 7200/25000 | Loss 1.388847 | Top1 Acc 65.75% | Top5 Acc 84.97%
Val | Iteration 7200/25000 | Loss 1.669079 | Top1 Acc 56.04% | Top5 Acc 82.01%
train | Iteration 7300/25000 | Loss 1.304221 | Top1 Acc 66.88% | Top5 Acc 85.81%
train | Iteration 7400/25000 | Loss 1.298779 | Top1 Acc 68.19% | Top5 Acc 85.72%
Val | Iteration 7400/25000 | Loss 1.648962 | Top1 Acc 56.77% | Top5 Acc 81.91%
train | Iteration 7500/25000 | Loss 1.297606 | Top1 Acc 68.09% | Top5 Acc 86.44%
train | Iteration 7600/25000 | Loss 1.320189 | Top1 Acc 66.84% | Top5 Acc 85.41%
Val | Iteration 7600/25000 | Loss 1.636201 | Top1 Acc 57.02% | Top5 Acc 82.25%
train | Iteration 7700/25000 | Loss 1.300310 | Top1 Acc 67.59% | Top5 Acc 86.06%
train | Iteration 7800/25000 | Loss 1.265170 | Top1 Acc 68.22% | Top5 Acc 86.44%
Val | Iteration 7800/25000 | Loss 1.622125 | Top1 Acc 57.40% | Top5 Acc 82.45%
train | Iteration 7900/25000 | Loss 1.290121 | Top1 Acc 67.91% | Top5 Acc 86.22%
train | Iteration 8000/25000 | Loss 1.282284 | Top1 Acc 67.88% | Top5 Acc 86.34%
Val | Iteration 8000/25000 | Loss 1.619073 | Top1 Acc 57.10% | Top5 Acc 82.74%
train | Iteration 8100/25000 | Loss 1.274328 | Top1 Acc 68.81% | Top5 Acc 86.66%
train | Iteration 8200/25000 | Loss 1.297041 | Top1 Acc 67.72% | Top5 Acc 86.22%
Val | Iteration 8200/25000 | Loss 1.619960 | Top1 Acc 57.21% | Top5 Acc 82.79%
train | Iteration 8300/25000 | Loss 1.239197 | Top1 Acc 69.41% | Top5 Acc 86.97%
train | Iteration 8400/25000 | Loss 1.241321 | Top1 Acc 68.75% | Top5 Acc 87.34%
Val | Iteration 8400/25000 | Loss 1.614164 | Top1 Acc 57.69% | Top5 Acc 82.54%
train | Iteration 8500/25000 | Loss 1.283733 | Top1 Acc 67.91% | Top5 Acc 86.22%
train | Iteration 8600/25000 | Loss 1.273225 | Top1 Acc 68.94% | Top5 Acc 86.12%
Val | Iteration 8600/25000 | Loss 1.576116 | Top1 Acc 58.44% | Top5 Acc 83.15%
train | Iteration 8700/25000 | Loss 1.231952 | Top1 Acc 69.09% | Top5 Acc 86.69%
train | Iteration 8800/25000 | Loss 1.221762 | Top1 Acc 68.69% | Top5 Acc 86.88%
Val | Iteration 8800/25000 | Loss 1.546329 | Top1 Acc 58.48% | Top5 Acc 83.72%
train | Iteration 8900/25000 | Loss 1.245878 | Top1 Acc 68.50% | Top5 Acc 86.78%
train | Iteration 9000/25000 | Loss 1.262964 | Top1 Acc 68.19% | Top5 Acc 86.69%
Val | Iteration 9000/25000 | Loss 1.529370 | Top1 Acc 59.33% | Top5 Acc 84.25%
train | Iteration 9100/25000 | Loss 1.251456 | Top1 Acc 68.88% | Top5 Acc 86.59%
train | Iteration 9200/25000 | Loss 1.266779 | Top1 Acc 68.81% | Top5 Acc 86.62%
Val | Iteration 9200/25000 | Loss 1.552533 | Top1 Acc 59.04% | Top5 Acc 83.67%
train | Iteration 9300/25000 | Loss 1.249510 | Top1 Acc 68.41% | Top5 Acc 86.91%
train | Iteration 9400/25000 | Loss 1.277845 | Top1 Acc 67.38% | Top5 Acc 86.44%
Val | Iteration 9400/25000 | Loss 1.542756 | Top1 Acc 59.11% | Top5 Acc 83.61%
train | Iteration 9500/25000 | Loss 1.221399 | Top1 Acc 69.53% | Top5 Acc 87.00%
train | Iteration 9600/25000 | Loss 1.213587 | Top1 Acc 68.97% | Top5 Acc 86.97%
Val | Iteration 9600/25000 | Loss 1.548796 | Top1 Acc 59.59% | Top5 Acc 83.66%
train | Iteration 9700/25000 | Loss 1.226512 | Top1 Acc 69.22% | Top5 Acc 86.41%
train | Iteration 9800/25000 | Loss 1.190247 | Top1 Acc 71.53% | Top5 Acc 87.44%
Val | Iteration 9800/25000 | Loss 1.517777 | Top1 Acc 60.10% | Top5 Acc 83.99%
train | Iteration 9900/25000 | Loss 1.158711 | Top1 Acc 70.47% | Top5 Acc 87.94%
train | Iteration 10000/25000 | Loss 1.180868 | Top1 Acc 70.81% | Top5 Acc 87.75%
Val | Iteration 10000/25000 | Loss 1.513492 | Top1 Acc 59.65% | Top5 Acc 84.21%
train | Iteration 10100/25000 | Loss 1.202593 | Top1 Acc 70.09% | Top5 Acc 86.94%
train | Iteration 10200/25000 | Loss 1.209630 | Top1 Acc 70.28% | Top5 Acc 86.66%
Val | Iteration 10200/25000 | Loss 1.485231 | Top1 Acc 60.36% | Top5 Acc 84.71%
train | Iteration 10300/25000 | Loss 1.217334 | Top1 Acc 68.88% | Top5 Acc 86.62%
train | Iteration 10400/25000 | Loss 1.194240 | Top1 Acc 69.62% | Top5 Acc 87.41%
Val | Iteration 10400/25000 | Loss 1.475256 | Top1 Acc 60.77% | Top5 Acc 84.67%
train | Iteration 10500/25000 | Loss 1.146477 | Top1 Acc 71.59% | Top5 Acc 88.09%
train | Iteration 10600/25000 | Loss 1.158115 | Top1 Acc 71.22% | Top5 Acc 88.09%
Val | Iteration 10600/25000 | Loss 1.468555 | Top1 Acc 61.04% | Top5 Acc 84.74%
train | Iteration 10700/25000 | Loss 1.165726 | Top1 Acc 71.50% | Top5 Acc 87.25%
train | Iteration 10800/25000 | Loss 1.140749 | Top1 Acc 70.94% | Top5 Acc 87.22%
Val | Iteration 10800/25000 | Loss 1.453611 | Top1 Acc 61.21% | Top5 Acc 85.17%
train | Iteration 10900/25000 | Loss 1.136949 | Top1 Acc 72.31% | Top5 Acc 88.25%
train | Iteration 11000/25000 | Loss 1.193657 | Top1 Acc 70.41% | Top5 Acc 86.34%
Val | Iteration 11000/25000 | Loss 1.466446 | Top1 Acc 60.81% | Top5 Acc 85.00%
train | Iteration 11100/25000 | Loss 1.157770 | Top1 Acc 70.47% | Top5 Acc 87.53%
train | Iteration 11200/25000 | Loss 1.129933 | Top1 Acc 71.72% | Top5 Acc 88.72%
Val | Iteration 11200/25000 | Loss 1.477846 | Top1 Acc 60.58% | Top5 Acc 84.72%
train | Iteration 11300/25000 | Loss 1.112463 | Top1 Acc 71.97% | Top5 Acc 88.97%
train | Iteration 11400/25000 | Loss 1.227636 | Top1 Acc 69.22% | Top5 Acc 86.31%
Val | Iteration 11400/25000 | Loss 1.457410 | Top1 Acc 60.70% | Top5 Acc 84.78%
train | Iteration 11500/25000 | Loss 1.159389 | Top1 Acc 70.41% | Top5 Acc 88.16%
train | Iteration 11600/25000 | Loss 1.188374 | Top1 Acc 69.91% | Top5 Acc 87.59%
Val | Iteration 11600/25000 | Loss 1.445183 | Top1 Acc 61.62% | Top5 Acc 84.70%
train | Iteration 11700/25000 | Loss 1.140330 | Top1 Acc 71.16% | Top5 Acc 88.28%
train | Iteration 11800/25000 | Loss 1.170433 | Top1 Acc 70.41% | Top5 Acc 87.19%
Val | Iteration 11800/25000 | Loss 1.413884 | Top1 Acc 62.44% | Top5 Acc 85.26%
train | Iteration 11900/25000 | Loss 1.167487 | Top1 Acc 71.28% | Top5 Acc 87.19%
train | Iteration 12000/25000 | Loss 1.090115 | Top1 Acc 73.12% | Top5 Acc 88.72%
Val | Iteration 12000/25000 | Loss 1.407981 | Top1 Acc 62.46% | Top5 Acc 85.74%
train | Iteration 12100/25000 | Loss 1.141657 | Top1 Acc 71.53% | Top5 Acc 87.31%
train | Iteration 12200/25000 | Loss 1.058581 | Top1 Acc 73.09% | Top5 Acc 88.56%
Val | Iteration 12200/25000 | Loss 1.404970 | Top1 Acc 62.20% | Top5 Acc 85.62%
train | Iteration 12300/25000 | Loss 1.126235 | Top1 Acc 72.41% | Top5 Acc 87.25%
train | Iteration 12400/25000 | Loss 1.118828 | Top1 Acc 71.69% | Top5 Acc 88.47%
Val | Iteration 12400/25000 | Loss 1.395293 | Top1 Acc 62.56% | Top5 Acc 85.84%
train | Iteration 12500/25000 | Loss 1.090050 | Top1 Acc 72.69% | Top5 Acc 88.62%
train | Iteration 12600/25000 | Loss 1.157934 | Top1 Acc 70.81% | Top5 Acc 87.06%
Val | Iteration 12600/25000 | Loss 1.408471 | Top1 Acc 62.05% | Top5 Acc 85.66%
train | Iteration 12700/25000 | Loss 1.098975 | Top1 Acc 72.91% | Top5 Acc 88.47%
train | Iteration 12800/25000 | Loss 1.082758 | Top1 Acc 72.16% | Top5 Acc 88.34%
Val | Iteration 12800/25000 | Loss 1.400975 | Top1 Acc 63.00% | Top5 Acc 85.90%
train | Iteration 12900/25000 | Loss 1.057955 | Top1 Acc 73.03% | Top5 Acc 89.00%
train | Iteration 13000/25000 | Loss 1.090958 | Top1 Acc 71.94% | Top5 Acc 88.62%
Val | Iteration 13000/25000 | Loss 1.386186 | Top1 Acc 63.08% | Top5 Acc 85.76%
train | Iteration 13100/25000 | Loss 1.063915 | Top1 Acc 72.72% | Top5 Acc 88.75%
train | Iteration 13200/25000 | Loss 1.079906 | Top1 Acc 72.44% | Top5 Acc 88.69%
Val | Iteration 13200/25000 | Loss 1.363364 | Top1 Acc 63.25% | Top5 Acc 86.22%
train | Iteration 13300/25000 | Loss 1.088475 | Top1 Acc 73.12% | Top5 Acc 89.00%
train | Iteration 13400/25000 | Loss 1.021255 | Top1 Acc 74.19% | Top5 Acc 89.66%
Val | Iteration 13400/25000 | Loss 1.368392 | Top1 Acc 63.76% | Top5 Acc 86.06%
train | Iteration 13500/25000 | Loss 1.073109 | Top1 Acc 73.28% | Top5 Acc 88.44%
train | Iteration 13600/25000 | Loss 1.054906 | Top1 Acc 73.62% | Top5 Acc 89.03%
Val | Iteration 13600/25000 | Loss 1.389981 | Top1 Acc 63.11% | Top5 Acc 85.86%
train | Iteration 13700/25000 | Loss 1.072940 | Top1 Acc 73.00% | Top5 Acc 88.50%
train | Iteration 13800/25000 | Loss 1.091569 | Top1 Acc 72.22% | Top5 Acc 88.12%
Val | Iteration 13800/25000 | Loss 1.371283 | Top1 Acc 63.60% | Top5 Acc 86.22%
train | Iteration 13900/25000 | Loss 1.083100 | Top1 Acc 72.53% | Top5 Acc 88.38%
train | Iteration 14000/25000 | Loss 1.056247 | Top1 Acc 73.81% | Top5 Acc 88.91%
Val | Iteration 14000/25000 | Loss 1.347683 | Top1 Acc 63.75% | Top5 Acc 86.71%
train | Iteration 14100/25000 | Loss 1.036875 | Top1 Acc 73.75% | Top5 Acc 89.28%
train | Iteration 14200/25000 | Loss 1.089288 | Top1 Acc 72.16% | Top5 Acc 87.81%
Val | Iteration 14200/25000 | Loss 1.344368 | Top1 Acc 63.99% | Top5 Acc 86.51%
train | Iteration 14300/25000 | Loss 1.050510 | Top1 Acc 73.78% | Top5 Acc 88.84%
train | Iteration 14400/25000 | Loss 1.028254 | Top1 Acc 73.69% | Top5 Acc 89.53%
Val | Iteration 14400/25000 | Loss 1.332535 | Top1 Acc 63.95% | Top5 Acc 86.76%
train | Iteration 14500/25000 | Loss 1.019483 | Top1 Acc 73.69% | Top5 Acc 89.25%
train | Iteration 14600/25000 | Loss 1.021181 | Top1 Acc 73.75% | Top5 Acc 89.50%
Val | Iteration 14600/25000 | Loss 1.329717 | Top1 Acc 64.59% | Top5 Acc 86.60%
train | Iteration 14700/25000 | Loss 1.037273 | Top1 Acc 73.56% | Top5 Acc 89.06%
train | Iteration 14800/25000 | Loss 1.055406 | Top1 Acc 74.38% | Top5 Acc 88.62%
Val | Iteration 14800/25000 | Loss 1.326312 | Top1 Acc 64.56% | Top5 Acc 87.05%
train | Iteration 14900/25000 | Loss 1.013825 | Top1 Acc 74.28% | Top5 Acc 89.09%
train | Iteration 15000/25000 | Loss 1.028302 | Top1 Acc 74.97% | Top5 Acc 89.38%
Val | Iteration 15000/25000 | Loss 1.321419 | Top1 Acc 64.62% | Top5 Acc 86.67%
train | Iteration 15100/25000 | Loss 1.033196 | Top1 Acc 74.22% | Top5 Acc 88.97%
train | Iteration 15200/25000 | Loss 1.005400 | Top1 Acc 74.44% | Top5 Acc 89.28%
Val | Iteration 15200/25000 | Loss 1.327418 | Top1 Acc 64.45% | Top5 Acc 86.85%
train | Iteration 15300/25000 | Loss 1.059095 | Top1 Acc 74.16% | Top5 Acc 88.88%
train | Iteration 15400/25000 | Loss 1.001584 | Top1 Acc 74.19% | Top5 Acc 89.25%
Val | Iteration 15400/25000 | Loss 1.313461 | Top1 Acc 64.90% | Top5 Acc 87.00%
train | Iteration 15500/25000 | Loss 1.040673 | Top1 Acc 73.94% | Top5 Acc 88.84%
train | Iteration 15600/25000 | Loss 0.982027 | Top1 Acc 75.72% | Top5 Acc 90.44%
Val | Iteration 15600/25000 | Loss 1.301420 | Top1 Acc 64.99% | Top5 Acc 87.15%
train | Iteration 15700/25000 | Loss 1.008641 | Top1 Acc 74.84% | Top5 Acc 89.12%
train | Iteration 15800/25000 | Loss 1.054927 | Top1 Acc 73.56% | Top5 Acc 88.91%
Val | Iteration 15800/25000 | Loss 1.298803 | Top1 Acc 65.12% | Top5 Acc 87.16%
train | Iteration 15900/25000 | Loss 0.960614 | Top1 Acc 75.84% | Top5 Acc 90.28%
train | Iteration 16000/25000 | Loss 0.990615 | Top1 Acc 74.97% | Top5 Acc 89.91%
Val | Iteration 16000/25000 | Loss 1.304021 | Top1 Acc 64.78% | Top5 Acc 87.04%
train | Iteration 16100/25000 | Loss 1.033738 | Top1 Acc 73.12% | Top5 Acc 89.44%
train | Iteration 16200/25000 | Loss 1.023727 | Top1 Acc 74.81% | Top5 Acc 89.06%
Val | Iteration 16200/25000 | Loss 1.300444 | Top1 Acc 65.08% | Top5 Acc 87.10%
train | Iteration 16300/25000 | Loss 0.982304 | Top1 Acc 73.59% | Top5 Acc 90.47%
train | Iteration 16400/25000 | Loss 1.015283 | Top1 Acc 74.19% | Top5 Acc 89.56%
Val | Iteration 16400/25000 | Loss 1.299399 | Top1 Acc 65.44% | Top5 Acc 86.96%
train | Iteration 16500/25000 | Loss 1.012248 | Top1 Acc 75.00% | Top5 Acc 89.38%
train | Iteration 16600/25000 | Loss 1.028298 | Top1 Acc 73.62% | Top5 Acc 88.84%
Val | Iteration 16600/25000 | Loss 1.275660 | Top1 Acc 65.39% | Top5 Acc 87.38%
train | Iteration 16700/25000 | Loss 1.061917 | Top1 Acc 73.12% | Top5 Acc 87.94%
train | Iteration 16800/25000 | Loss 0.969446 | Top1 Acc 75.78% | Top5 Acc 89.56%
Val | Iteration 16800/25000 | Loss 1.290605 | Top1 Acc 65.41% | Top5 Acc 87.12%
train | Iteration 16900/25000 | Loss 0.988103 | Top1 Acc 74.56% | Top5 Acc 89.47%
train | Iteration 17000/25000 | Loss 1.002096 | Top1 Acc 74.06% | Top5 Acc 89.88%
Val | Iteration 17000/25000 | Loss 1.279031 | Top1 Acc 65.85% | Top5 Acc 87.17%
train | Iteration 17100/25000 | Loss 0.957123 | Top1 Acc 76.75% | Top5 Acc 89.94%
train | Iteration 17200/25000 | Loss 1.014144 | Top1 Acc 75.56% | Top5 Acc 89.44%
Val | Iteration 17200/25000 | Loss 1.288263 | Top1 Acc 65.70% | Top5 Acc 87.15%
train | Iteration 17300/25000 | Loss 0.989181 | Top1 Acc 74.03% | Top5 Acc 89.94%
train | Iteration 17400/25000 | Loss 1.000688 | Top1 Acc 74.91% | Top5 Acc 89.75%
Val | Iteration 17400/25000 | Loss 1.278470 | Top1 Acc 65.75% | Top5 Acc 87.47%
train | Iteration 17500/25000 | Loss 0.995368 | Top1 Acc 75.31% | Top5 Acc 89.41%
train | Iteration 17600/25000 | Loss 0.925867 | Top1 Acc 76.94% | Top5 Acc 90.66%
Val | Iteration 17600/25000 | Loss 1.283176 | Top1 Acc 65.91% | Top5 Acc 87.19%
train | Iteration 17700/25000 | Loss 0.992478 | Top1 Acc 74.53% | Top5 Acc 89.47%
train | Iteration 17800/25000 | Loss 0.999863 | Top1 Acc 75.31% | Top5 Acc 89.47%
Val | Iteration 17800/25000 | Loss 1.268268 | Top1 Acc 65.99% | Top5 Acc 87.67%
train | Iteration 17900/25000 | Loss 0.945658 | Top1 Acc 76.50% | Top5 Acc 89.97%
train | Iteration 18000/25000 | Loss 0.944557 | Top1 Acc 75.38% | Top5 Acc 90.50%
Val | Iteration 18000/25000 | Loss 1.274309 | Top1 Acc 66.12% | Top5 Acc 87.83%
train | Iteration 18100/25000 | Loss 0.973753 | Top1 Acc 75.00% | Top5 Acc 89.91%
train | Iteration 18200/25000 | Loss 0.944984 | Top1 Acc 75.44% | Top5 Acc 90.75%
Val | Iteration 18200/25000 | Loss 1.266997 | Top1 Acc 66.30% | Top5 Acc 87.46%
train | Iteration 18300/25000 | Loss 0.990513 | Top1 Acc 74.94% | Top5 Acc 89.09%
train | Iteration 18400/25000 | Loss 0.932607 | Top1 Acc 75.94% | Top5 Acc 90.25%
Val | Iteration 18400/25000 | Loss 1.263463 | Top1 Acc 66.53% | Top5 Acc 87.67%
train | Iteration 18500/25000 | Loss 0.975873 | Top1 Acc 76.12% | Top5 Acc 89.62%
train | Iteration 18600/25000 | Loss 0.951671 | Top1 Acc 75.50% | Top5 Acc 89.81%
Val | Iteration 18600/25000 | Loss 1.262801 | Top1 Acc 66.01% | Top5 Acc 87.75%
train | Iteration 18700/25000 | Loss 0.968311 | Top1 Acc 75.41% | Top5 Acc 89.75%
train | Iteration 18800/25000 | Loss 0.954471 | Top1 Acc 76.16% | Top5 Acc 90.00%
Val | Iteration 18800/25000 | Loss 1.249287 | Top1 Acc 66.53% | Top5 Acc 87.65%
train | Iteration 18900/25000 | Loss 0.950407 | Top1 Acc 76.53% | Top5 Acc 89.69%
train | Iteration 19000/25000 | Loss 0.965161 | Top1 Acc 76.22% | Top5 Acc 89.38%
Val | Iteration 19000/25000 | Loss 1.251023 | Top1 Acc 66.60% | Top5 Acc 87.74%
train | Iteration 19100/25000 | Loss 0.956585 | Top1 Acc 76.62% | Top5 Acc 89.62%
train | Iteration 19200/25000 | Loss 0.983029 | Top1 Acc 75.69% | Top5 Acc 89.34%
Val | Iteration 19200/25000 | Loss 1.253512 | Top1 Acc 66.24% | Top5 Acc 87.74%
train | Iteration 19300/25000 | Loss 0.950583 | Top1 Acc 75.97% | Top5 Acc 90.09%
train | Iteration 19400/25000 | Loss 0.947108 | Top1 Acc 76.69% | Top5 Acc 90.16%
Val | Iteration 19400/25000 | Loss 1.253031 | Top1 Acc 66.47% | Top5 Acc 87.80%
train | Iteration 19500/25000 | Loss 0.943186 | Top1 Acc 76.00% | Top5 Acc 90.59%
train | Iteration 19600/25000 | Loss 0.896366 | Top1 Acc 77.09% | Top5 Acc 91.00%
Val | Iteration 19600/25000 | Loss 1.241427 | Top1 Acc 66.44% | Top5 Acc 87.96%
train | Iteration 19700/25000 | Loss 0.982105 | Top1 Acc 74.59% | Top5 Acc 89.47%
train | Iteration 19800/25000 | Loss 0.950682 | Top1 Acc 76.56% | Top5 Acc 89.97%
Val | Iteration 19800/25000 | Loss 1.241762 | Top1 Acc 66.67% | Top5 Acc 87.97%
train | Iteration 19900/25000 | Loss 0.962276 | Top1 Acc 76.75% | Top5 Acc 89.56%
train | Iteration 20000/25000 | Loss 0.892998 | Top1 Acc 77.56% | Top5 Acc 91.06%
Val | Iteration 20000/25000 | Loss 1.245469 | Top1 Acc 66.54% | Top5 Acc 87.92%
train | Iteration 20100/25000 | Loss 0.924795 | Top1 Acc 76.78% | Top5 Acc 90.50%
train | Iteration 20200/25000 | Loss 0.920203 | Top1 Acc 76.94% | Top5 Acc 90.69%
Val | Iteration 20200/25000 | Loss 1.232449 | Top1 Acc 66.84% | Top5 Acc 87.86%
train | Iteration 20300/25000 | Loss 0.945352 | Top1 Acc 76.34% | Top5 Acc 90.03%
train | Iteration 20400/25000 | Loss 0.987098 | Top1 Acc 75.47% | Top5 Acc 89.44%
Val | Iteration 20400/25000 | Loss 1.228737 | Top1 Acc 67.20% | Top5 Acc 88.09%
train | Iteration 20500/25000 | Loss 0.986011 | Top1 Acc 75.19% | Top5 Acc 89.56%
train | Iteration 20600/25000 | Loss 0.907340 | Top1 Acc 76.94% | Top5 Acc 90.94%
Val | Iteration 20600/25000 | Loss 1.229042 | Top1 Acc 67.08% | Top5 Acc 88.00%
train | Iteration 20700/25000 | Loss 0.942002 | Top1 Acc 76.12% | Top5 Acc 89.97%
train | Iteration 20800/25000 | Loss 0.998997 | Top1 Acc 75.31% | Top5 Acc 89.12%
Val | Iteration 20800/25000 | Loss 1.225043 | Top1 Acc 67.34% | Top5 Acc 88.11%
train | Iteration 20900/25000 | Loss 0.940536 | Top1 Acc 76.28% | Top5 Acc 89.94%
train | Iteration 21000/25000 | Loss 0.932725 | Top1 Acc 76.56% | Top5 Acc 90.88%
Val | Iteration 21000/25000 | Loss 1.231176 | Top1 Acc 66.88% | Top5 Acc 88.04%
train | Iteration 21100/25000 | Loss 0.945442 | Top1 Acc 75.97% | Top5 Acc 89.91%
train | Iteration 21200/25000 | Loss 0.937451 | Top1 Acc 76.69% | Top5 Acc 90.53%
Val | Iteration 21200/25000 | Loss 1.228143 | Top1 Acc 67.01% | Top5 Acc 88.22%
train | Iteration 21300/25000 | Loss 0.944830 | Top1 Acc 76.22% | Top5 Acc 90.09%
train | Iteration 21400/25000 | Loss 0.932478 | Top1 Acc 76.28% | Top5 Acc 90.34%
Val | Iteration 21400/25000 | Loss 1.215743 | Top1 Acc 67.19% | Top5 Acc 88.20%
train | Iteration 21500/25000 | Loss 0.958118 | Top1 Acc 75.84% | Top5 Acc 90.06%
train | Iteration 21600/25000 | Loss 0.887347 | Top1 Acc 77.75% | Top5 Acc 90.94%
Val | Iteration 21600/25000 | Loss 1.216781 | Top1 Acc 67.41% | Top5 Acc 88.24%
train | Iteration 21700/25000 | Loss 0.913270 | Top1 Acc 77.16% | Top5 Acc 90.41%
train | Iteration 21800/25000 | Loss 0.928933 | Top1 Acc 76.62% | Top5 Acc 90.19%
Val | Iteration 21800/25000 | Loss 1.220840 | Top1 Acc 67.30% | Top5 Acc 88.06%
train | Iteration 21900/25000 | Loss 0.913789 | Top1 Acc 77.12% | Top5 Acc 90.28%
train | Iteration 22000/25000 | Loss 0.917056 | Top1 Acc 77.16% | Top5 Acc 90.28%
Val | Iteration 22000/25000 | Loss 1.224896 | Top1 Acc 67.19% | Top5 Acc 88.06%
train | Iteration 22100/25000 | Loss 0.941704 | Top1 Acc 76.50% | Top5 Acc 90.19%
train | Iteration 22200/25000 | Loss 0.914656 | Top1 Acc 77.00% | Top5 Acc 90.81%
Val | Iteration 22200/25000 | Loss 1.215935 | Top1 Acc 67.24% | Top5 Acc 88.12%
train | Iteration 22300/25000 | Loss 0.948636 | Top1 Acc 76.22% | Top5 Acc 89.31%
train | Iteration 22400/25000 | Loss 0.927429 | Top1 Acc 76.75% | Top5 Acc 90.44%
Val | Iteration 22400/25000 | Loss 1.211662 | Top1 Acc 67.49% | Top5 Acc 88.24%
train | Iteration 22500/25000 | Loss 0.919180 | Top1 Acc 76.75% | Top5 Acc 90.53%
train | Iteration 22600/25000 | Loss 0.924888 | Top1 Acc 76.78% | Top5 Acc 90.81%
Val | Iteration 22600/25000 | Loss 1.214346 | Top1 Acc 67.51% | Top5 Acc 88.17%
train | Iteration 22700/25000 | Loss 0.890999 | Top1 Acc 77.78% | Top5 Acc 91.12%
train | Iteration 22800/25000 | Loss 0.898860 | Top1 Acc 77.00% | Top5 Acc 90.59%
Val | Iteration 22800/25000 | Loss 1.222651 | Top1 Acc 67.20% | Top5 Acc 88.16%
train | Iteration 22900/25000 | Loss 0.918586 | Top1 Acc 76.50% | Top5 Acc 90.22%
train | Iteration 23000/25000 | Loss 0.925508 | Top1 Acc 76.97% | Top5 Acc 90.53%
Val | Iteration 23000/25000 | Loss 1.216270 | Top1 Acc 67.47% | Top5 Acc 88.20%
train | Iteration 23100/25000 | Loss 0.921308 | Top1 Acc 76.66% | Top5 Acc 90.28%
train | Iteration 23200/25000 | Loss 0.969785 | Top1 Acc 75.50% | Top5 Acc 89.72%
Val | Iteration 23200/25000 | Loss 1.222297 | Top1 Acc 67.15% | Top5 Acc 88.01%
train | Iteration 23300/25000 | Loss 0.910824 | Top1 Acc 77.22% | Top5 Acc 90.59%
train | Iteration 23400/25000 | Loss 0.933123 | Top1 Acc 76.44% | Top5 Acc 90.84%
Val | Iteration 23400/25000 | Loss 1.214442 | Top1 Acc 67.45% | Top5 Acc 88.28%
train | Iteration 23500/25000 | Loss 0.926926 | Top1 Acc 77.19% | Top5 Acc 90.47%
train | Iteration 23600/25000 | Loss 0.903745 | Top1 Acc 76.81% | Top5 Acc 91.16%
Val | Iteration 23600/25000 | Loss 1.214695 | Top1 Acc 67.29% | Top5 Acc 88.17%
train | Iteration 23700/25000 | Loss 0.936944 | Top1 Acc 76.06% | Top5 Acc 89.62%
train | Iteration 23800/25000 | Loss 0.872128 | Top1 Acc 77.44% | Top5 Acc 91.53%
Val | Iteration 23800/25000 | Loss 1.212442 | Top1 Acc 67.47% | Top5 Acc 88.20%
train | Iteration 23900/25000 | Loss 0.887223 | Top1 Acc 77.62% | Top5 Acc 90.84%
train | Iteration 24000/25000 | Loss 0.921953 | Top1 Acc 76.66% | Top5 Acc 90.16%
Val | Iteration 24000/25000 | Loss 1.216106 | Top1 Acc 67.17% | Top5 Acc 88.17%
train | Iteration 24100/25000 | Loss 0.906691 | Top1 Acc 77.44% | Top5 Acc 90.53%
train | Iteration 24200/25000 | Loss 0.883175 | Top1 Acc 77.06% | Top5 Acc 90.69%
Val | Iteration 24200/25000 | Loss 1.216395 | Top1 Acc 67.26% | Top5 Acc 88.17%
train | Iteration 24300/25000 | Loss 0.880643 | Top1 Acc 77.22% | Top5 Acc 91.22%
train | Iteration 24400/25000 | Loss 0.899472 | Top1 Acc 77.94% | Top5 Acc 90.97%
Val | Iteration 24400/25000 | Loss 1.211598 | Top1 Acc 67.47% | Top5 Acc 88.20%
train | Iteration 24500/25000 | Loss 0.941807 | Top1 Acc 76.00% | Top5 Acc 89.78%
train | Iteration 24600/25000 | Loss 0.971310 | Top1 Acc 76.44% | Top5 Acc 89.84%
Val | Iteration 24600/25000 | Loss 1.210680 | Top1 Acc 67.36% | Top5 Acc 88.30%
train | Iteration 24700/25000 | Loss 0.919928 | Top1 Acc 77.44% | Top5 Acc 90.16%
train | Iteration 24800/25000 | Loss 0.917149 | Top1 Acc 77.59% | Top5 Acc 90.09%
Val | Iteration 24800/25000 | Loss 1.205702 | Top1 Acc 67.50% | Top5 Acc 88.34%
train | Iteration 24900/25000 | Loss 0.871169 | Top1 Acc 77.84% | Top5 Acc 91.72%
train | Iteration 25000/25000 | Loss 0.924589 | Top1 Acc 77.00% | Top5 Acc 90.22%
Val | Iteration 25000/25000 | Loss 1.211575 | Top1 Acc 67.34% | Top5 Acc 88.60%
Training complete in 44m 52s
Best val Acc: 67.51%
testLast Loss: 1.2113 Top1 Acc: 67.33% Top5 Acc: 88.60%
testBest Loss: 1.2143 Top1 Acc: 67.51% Top5 Acc: 88.17%
